{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Data Cleansing <br>\n",
    "\n",
    "Name: Manmeet Singh <br>\n",
    "Id: 30749476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology<br>\n",
    "\n",
    "I have use non graphical EDA to analyze the datasets except for outlier data. <br>\n",
    "I will be explaning my Methodology step by step for each cell for better understanding.<br>\n",
    "Please note for few cells output has been printed for EDA and explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data file for dirty data and Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data = pd.read_csv('30749476_dirty_data.csv')\n",
    "\n",
    "warehouse_data = pd.read_csv('warehouses.csv')\n",
    "# convert dataframe to dictionary\n",
    "warehouse_dict = warehouse_data.to_dict()\n",
    "# dictionary of Nickolson with it's coordinate \n",
    "Nickolson = {warehouse_dict['names'][0]:(warehouse_dict['lat'][0],warehouse_dict['lon'][0])}\n",
    "# dictionary of Thompson with it's coordinate\n",
    "Thompson = {warehouse_dict['names'][1]:(warehouse_dict['lat'][1],warehouse_dict['lon'][1])}\n",
    "# dictionary of Bakers with it's coordinate\n",
    "Bakers = {warehouse_dict['names'][2]:(warehouse_dict['lat'][2],warehouse_dict['lon'][2])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1<br>\n",
    "**Check the information, it provides how many entries, and columns in dataset. Provide the type of each column and if any null values.**<br>\n",
    "As we can see there are 500 entries and 16 columms with no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 <br>\n",
    "**Let's perform some more analysis**<br> \n",
    "1. From the description below for numeric columns, we can see the min, max, std, count for all numeric columns.<br>\n",
    "2. WE can see that customer_lat column has max value of 145.007284 and customer_long has min value -37.826093, which does not seem right.<br>\n",
    "3. For other columns we can't see any such information, which for npow seems good, but can't be guaranteed. For them we will perform other type of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3<br>\n",
    "**Let's perform analysis on categorical columns**<br>\n",
    "\n",
    "1. Column date,nearest_warehouse,shopping_cart,season has some duplicate entries. We will determine if they are good or needs to be removed.<br>\n",
    "2. customer_id also have 18 duplicate entries. We will analyze if they are repeated rows or different because it is possible same customer has made order more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty_data[dirty_data['customer_id'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 <br>\n",
    "**Get Unique values for Season Column**<br>\n",
    "Below we can see it has 8 unique values, but same 4 season with lower case format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data['season'].unique()  # get unqiue values for season column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 <br>\n",
    "**Get Unique values for Season Column**<br>\n",
    "Below we can see it has 6 unique values, but same 3 warehouse with lower case format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data['nearest_warehouse'].unique() # # get unqiue values for nearest_warehouse column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6<br>\n",
    "**Replace the lower format elements with their respective correct format for nearest_warehouse and season column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the warehouse name to of same format\n",
    "dirty_data['nearest_warehouse'] = dirty_data['nearest_warehouse'].replace({'thompson':'Thompson','nickolson':'Nickolson',\n",
    "                                                                          'bakers': 'Bakers'})\n",
    "# update the season name to of same format\n",
    "dirty_data['season'] = dirty_data['season'].replace({'summer':'Summer','winter':'Winter',\n",
    "                                                     'autumn': 'Autumn', 'spring':'Spring'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 <br>\n",
    "**Date column might have different formats, so creat a dateConversion fucntion which detect the date format using regex and convert the date finally to YYYY-mm-dd format. After that change the column type from object to datetime format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the format of date\n",
    "def dateConversion(x):\n",
    "    \n",
    "    if re.match(r\"^\\d{1,2}/\", x['date']):\n",
    "        dateObj = datetime.strptime(x['date'],'%d/%m/%Y')\n",
    "    try:\n",
    "        if re.match(r'[0-9|/]+', x['date']):\n",
    "            dateObj = datetime.strptime(x['date'],'%Y-%m-%d')\n",
    "    except:\n",
    "        try:\n",
    "            if re.match(r'[0-9|/]+', x['date']):\n",
    "                dateObj = datetime.strptime(x['date'],'%d-%m-%Y')\n",
    "        except:\n",
    "            dateObj = datetime.strptime(x['date'],'%Y-%d-%m')\n",
    "    # convert the date to YYYY-mm-dd format\n",
    "    date = dateObj.strftime('%Y-%m-%d')\n",
    "    return date\n",
    "\n",
    "# apply dateconversion function to date column of dirt data\n",
    "dirty_data['date'] = dirty_data.apply(dateConversion, axis=1)\n",
    "# change the format of date col from object to datetime\n",
    "dirty_data['date'] = pd.to_datetime(dirty_data['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Customer coordinates<br>\n",
    "From step 2 we know that customer_lat and customer_long have some incorrect values, they contain respectively each other value. To make it correct we will swap the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the latitude and longitude values for customer_lat and customer_long columns where they have incorrect coordinates\n",
    "dirty_data['customer_lat'],dirty_data['customer_long'] = np.where(dirty_data['customer_lat'] > 0, \n",
    "                                      (dirty_data['customer_long'],dirty_data['customer_lat']),\n",
    "                                      (dirty_data['customer_lat'],dirty_data['customer_long'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Duplicate Entries<br>\n",
    "1. From Step 2 we know customer_id have some duplicate entrie. Since these id's are unique we will check if any entry is repeated.<br>\n",
    "2. Below We can see the dataframe with duplicate entries only<br>\n",
    "3. No entry is repeated, so they are fair.<br>\n",
    "4. For customer ID0846591613 (index 52,97), have same coordinates but different nearest warehouse. **It means it is possible that other customer might also have same issue. We will rectify it in next step, Step 10.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe for duplicate customer id\n",
    "ids = dirty_data[\"customer_id\"]\n",
    "# sort data frame with customer_id\n",
    "dirty_data[ids.isin(ids[ids.duplicated()])].sort_values(by=['customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Check correct Nearest Warehouse<br>\n",
    "1. Issue found in **Step 9, part 4**. We will rectify it by following method: <br>\n",
    "    a. Create a fucntion **\"Kilometer\"** to calculate distance from customer house to all warehouses.<br>\n",
    "    b. Create a fucntion **\"warehouse\"**, we will get the coordinate of warehouses and customer. Check distance of each warehouse from customer home and take the minimum distance.<br>\n",
    "    c. Pass a condition if calculated distance is equal to current distance, keep the current warehouse, if not then replace the current warehouse with update warehouse information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to calculate distance between two coordinates\n",
    "# referred to https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude\n",
    "def kilometers(lat1,lat2,long1,long2,Radius):\n",
    "    longitude = long2 - long1\n",
    "    latitude = lat2 - lat1\n",
    "    # calculate arc\n",
    "    arc = (sin(latitude/2))**2 + cos(lat1) * cos(lat2) * (sin(longitude/2))**2\n",
    "    circumfrence = 2 * atan2(sqrt(arc), sqrt(1-arc))\n",
    "    # distance calculation\n",
    "    actual_dictance = Radius * circumfrence\n",
    "    \n",
    "    return round(actual_dictance,4)\n",
    "\n",
    "def warehouse(x):\n",
    "    # empty list\n",
    "    kiloList = [] \n",
    "    Radius = 6378 # earth radius\n",
    "    # customer latitude\n",
    "    lat2 = radians(x['customer_lat'])\n",
    "    # customer longitude\n",
    "    long2 = radians(x['customer_long'])\n",
    "    # warehouse list\n",
    "    warehouseList = ['Nickolson','Thompson','Bakers']\n",
    "    # initiate for loop\n",
    "    for location in warehouseList:\n",
    "        # if Nickolson warehouse\n",
    "        if location == 'Nickolson':\n",
    "            # get Nickolson coordinates\n",
    "            lat1 = radians(Nickolson['Nickolson'][0])\n",
    "            long1 = radians(Nickolson['Nickolson'][1])\n",
    "            # calculate distance with customer location\n",
    "            distance = kilometers(lat1,lat2,long1,long2,Radius)\n",
    "            # append list\n",
    "            kiloList.append(distance)\n",
    "        # if Thompson warehouse\n",
    "        if location == 'Thompson':\n",
    "            # get Thompson coordinates\n",
    "            lat1 = radians(Thompson['Thompson'][0])\n",
    "            long1 = radians(Thompson['Thompson'][1])\n",
    "             # calculate distance with customer location\n",
    "            distance = kilometers(lat1,lat2,long1,long2,Radius)\n",
    "            # append list\n",
    "            kiloList.append(distance)\n",
    "\n",
    "        if location == 'Bakers':\n",
    "            # get Bakers coordinates\n",
    "            lat1 = radians(Bakers['Bakers'][0])\n",
    "            long1 = radians(Bakers['Bakers'][1])\n",
    "            # calculate distance with customer location\n",
    "            distance = kilometers(lat1,lat2,long1,long2,Radius)\n",
    "            # append list\n",
    "            kiloList.append(distance)\n",
    "    # minimum value from the list\n",
    "    min_distance = min(kiloList)\n",
    "    # get index of minimum value\n",
    "    ind = kiloList.index(min_distance)\n",
    "    # get the warehouse based on the index found through minimum distance\n",
    "    actual_warehouse = warehouseList[ind]\n",
    "    \n",
    "    if x['nearest_warehouse'] == actual_warehouse: # if calculated distnce is current, return current distance\n",
    "        return x['nearest_warehouse']\n",
    "    else:\n",
    "        return actual_warehouse # else return calculated distance\n",
    "\n",
    "# apply warehouse function on nearest_warehouse\n",
    "dirty_data['nearest_warehouse'] = dirty_data.apply(warehouse,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11: Re check if issue found in step 9 rectified by step 10.<br>\n",
    "We will check again if the issue of warehouse have been rectified for user ID0846591613 or not. We can see below, it has been rectified and other users also have correct information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe for duplicate customer id\n",
    "ids = dirty_data[\"customer_id\"]\n",
    "# sort data frame with customer_id\n",
    "dirty_data[ids.isin(ids[ids.duplicated()])].sort_values(by=['customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12: Check Total Order Price. <br>\n",
    "**Similarly we will check for anomalies if any total order price is incorrect.**<br>\n",
    "1. We cannot determine if total order price has any anomalies from summary. So we will perform following steps.<br>\n",
    "    a. Create function **\"order\"** which calculate total order price from order price minus discounted price plus delivery charges.<br>\n",
    "    b. Now, we check if current total price is equal to calculated total price, keep the current value else replace it with correct calculated value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate total order price\n",
    "def order(x):\n",
    "    # total order price\n",
    "    actual_order_price = x['order_price']*(1-x['coupon_discount']/100)+x['delivery_charges']\n",
    "    # if current price equal calculated, keep current\n",
    "    if actual_order_price == x['order_total']:\n",
    "        return x['order_total']\n",
    "    else:\n",
    "        return actual_order_price # else update calculated value\n",
    "\n",
    "dirty_data['order_total'] = dirty_data.apply(order, axis=1) # apply order fucntion on order_total col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spring - the three transition months September, October and November.<br>\n",
    "Summer - the three hottest months December, January and February.<br>\n",
    "Autumn - the transition months March, April and May.<br>\n",
    "Winter - the three coldest months June, July and August.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13: Check correct Season based on Month of Date. <br>\n",
    "1. Since we have already corrected the format of season values in Step 6. Now we will check based on date if the current season is correct or not. <br>\n",
    "2. First we get list of months for each season.<br>\n",
    "3. Create function **\"season\"**, in this fucntion we will first fetch the month of the date.<br>\n",
    "4. After that we will check in which season list this month belongs (Spring, Summer, Autumn, Winter).<br>\n",
    "5. After gettting the season in above step, compare it with the current value, if same keep current value, else update it with new value found in above step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining months as list for all seasons\n",
    "Spring = [9,10,11]\n",
    "Summer = [12,1,2]\n",
    "Autumn = [3,4,5]\n",
    "Winter = [6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(x):\n",
    "    # get the month from date column\n",
    "    month = int(str(x['date']).split('-')[1])\n",
    "    \n",
    "    if month in Spring:\n",
    "        # if current value is Spring, keep it, else update it.\n",
    "        if x['season'] == 'Spring':\n",
    "            return x['season']\n",
    "        else:\n",
    "            return 'Spring'\n",
    "    elif month in Summer:\n",
    "        # if current value is Summer, keep it, else update it.\n",
    "        if x['season'] == 'Summer':\n",
    "            return x['season']\n",
    "        else:\n",
    "            return 'Summer'\n",
    "    elif month in Autumn:\n",
    "        # if current value is Autumn, keep it, else update it.\n",
    "        if x['season'] == 'Autumn':\n",
    "            return x['season']\n",
    "        else:\n",
    "            return 'Autumn'\n",
    "    elif month in Winter:\n",
    "        # if current value is Winter, keep it, else update it.\n",
    "        if x['season'] == 'Winter':\n",
    "            return x['season']\n",
    "        else:\n",
    "            return 'Winter'\n",
    "dirty_data['season'] = dirty_data.apply(season,axis=1) # apply season function on season col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 14. Get the brands from Shopping Cart<br>\n",
    "In this step we will check if the items in shopping cart is less than, more than or equal to 10. Also if each item has different format or not.<br>\n",
    "1. First get the value from each cell, convert the string of list to List format.<br>\n",
    "2. Add each item in a list and finally take a set to get the unique values. We can see below we have 10 items with no different format or such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_list = []\n",
    "for items in dirty_data['shopping_cart']:\n",
    "    for item in eval(items):\n",
    "        cart_list.append(item[0])\n",
    "set(cart_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15: Check distance to nearest warehouse.<br>\n",
    "1. As we have rectified the nearest warehouse location for each customer. We need to rectify the distance as well.<br>\n",
    "2. Create a function **\"distance\"**, now check which is the nearest warehouse to the customer based on the coordinates.<br>\n",
    "3. If the calculated distance is equal to current value, keep current value, else replace it with distance calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x):\n",
    "    Radius = 6378 # Earth Radius\n",
    "    if x['nearest_warehouse'] == 'Nickolson':\n",
    "        # if nearest warehouse is Nickolson, get its coordinate\n",
    "        lat1 = radians(Nickolson['Nickolson'][0])\n",
    "        long1 = radians(Nickolson['Nickolson'][1])\n",
    "        \n",
    "    if x['nearest_warehouse'] == 'Thompson':\n",
    "        # if nearest warehouse is Thompson, get its coordinate\n",
    "        lat1 = radians(Thompson['Thompson'][0])\n",
    "        long1 = radians(Thompson['Thompson'][1])\n",
    "    \n",
    "    if x['nearest_warehouse'] == 'Bakers':\n",
    "        # if nearest warehouse is Bakers, get its coordinate\n",
    "        lat1 = radians(Bakers['Bakers'][0])\n",
    "        long1 = radians(Bakers['Bakers'][1])\n",
    "    # customer coordinates\n",
    "    lat2 = radians(x['customer_lat'])\n",
    "    long2 = radians(x['customer_long'])\n",
    "\n",
    "    longitude = long2 - long1\n",
    "    latitude = lat2 - lat1\n",
    "    # arc calculation\n",
    "    arc = (sin(latitude/2))**2 + cos(lat1) * cos(lat2) * (sin(longitude/2))**2\n",
    "    circumfrence = 2 * atan2(sqrt(arc), sqrt(1-arc))\n",
    "    # actual distance\n",
    "    actual_dictance = Radius * circumfrence\n",
    "    \n",
    "    # if calculated distance is current distance, keep it, else update with calculated value\n",
    "    if actual_dictance == x['distance_to_nearest_warehouse']:\n",
    "        return x['distance_to_nearest_warehouse']\n",
    "    else:\n",
    "        return round(actual_dictance,4)\n",
    "\n",
    "# apply distance function on distance_to_nearest_warehouse\n",
    "dirty_data['distance_to_nearest_warehouse'] = dirty_data.apply(distance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take the summary of numeric values again.<br>\n",
    "We can see statistical values has been updated for cusstomer coordinates, and order_total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take the summary of categorical values again.\n",
    "¶\n",
    "We can see values has been updated for nearest_warehouse coordinates, and season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 16: Customer happiness<br>\n",
    "We will check based on compound polarity score obtain from customer review, whether customer is happy or not.<br>\n",
    "1. Create function polarity, call SentimentIntensityAnalyzer() and initialize the object. Check the polarity score of compund for each review. If it is more than 0.05 customer is happy, and disappointed otherwise.<br>\n",
    "2. If current value is equal to calculated value, keep current value, else replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the compound polarity score for reviews\n",
    "def polarity(x):\n",
    "    # initilize object for polarity score\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    # If review is None keep current happy customer value\n",
    "    if ('none' in x['latest_customer_review'] or 'None' in x['latest_customer_review']) and len(x['latest_customer_review'].split()) <= 2:\n",
    "        return x['is_happy_customer']\n",
    "    # get the polarity score\n",
    "    score = sid.polarity_scores(x['latest_customer_review'])\n",
    "    # if score is >= 0.05, customer is happy\n",
    "    if score['compound'] >= 0.05:\n",
    "        polarity = True\n",
    "        if x['is_happy_customer'] is True: # if already True, keep current value\n",
    "            return x['is_happy_customer']\n",
    "        else:\n",
    "            return polarity # else update with True\n",
    "    else: # customer is not happy\n",
    "        polarity = False\n",
    "        if x['is_happy_customer'] is False: # if already false, keep current value\n",
    "            return x['is_happy_customer']\n",
    "        else:\n",
    "            return polarity # else update with False\n",
    "        \n",
    "# apply polarity function on is_happy_customer\n",
    "dirty_data['is_happy_customer'] = dirty_data.apply(polarity,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Step 17: Order Price Valuation<br>\n",
    " It is not possible to evaluate order_price. Since it is not possible to determine which row is correct we cannot evaluate the value of order_price column. So, I am considering that they are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_data.to_csv('30749476_dirty_data_solution.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 18: Summary of Missing Data<br>\n",
    "Since all the values are correct in this we only concered about missing values. Which we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = pd.read_csv('30749476_missing_data.csv')\n",
    "missing_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 19: Total NaN values in each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 20: Fill Nearest Warehouse.<br>\n",
    "We will use same method used in **\"Step 10: Check correct Nearest Warehouse\"**. Only difference here is we return nearest warehouse name only for NaN or null values and existing values in column will remain same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_warehouse(x):\n",
    "    # empty list\n",
    "    kiloList = [] \n",
    "    Radius = 6378 # earth radius\n",
    "    # customer latitude\n",
    "    lat2 = radians(x['customer_lat'])\n",
    "    # customer longitude\n",
    "    long2 = radians(x['customer_long'])\n",
    "    # warehouse list\n",
    "    warehouseList = ['Nickolson','Thompson','Bakers']\n",
    "    # initiate for loop\n",
    "    for location in warehouseList:\n",
    "        # if Nickolson warehouse\n",
    "        if location == 'Nickolson':\n",
    "            # get Nickolson coordinates\n",
    "            lat1 = radians(Nickolson['Nickolson'][0])\n",
    "            long1 = radians(Nickolson['Nickolson'][1])\n",
    "            # calculate distance with customer location\n",
    "            distance = kilometers(lat1,lat2,long1,long2,Radius)\n",
    "            # append list\n",
    "            kiloList.append(distance)\n",
    "        # if Thompson warehouse\n",
    "        if location == 'Thompson':\n",
    "            # get Thompson coordinates\n",
    "            lat1 = radians(Thompson['Thompson'][0])\n",
    "            long1 = radians(Thompson['Thompson'][1])\n",
    "             # calculate distance with customer location\n",
    "            distance = kilometers(lat1,lat2,long1,long2,Radius)\n",
    "            # append list\n",
    "            kiloList.append(distance)\n",
    "\n",
    "        if location == 'Bakers':\n",
    "            # get Bakers coordinates\n",
    "            lat1 = radians(Bakers['Bakers'][0])\n",
    "            long1 = radians(Bakers['Bakers'][1])\n",
    "            # calculate distance with customer location\n",
    "            distance = kilometers(lat1,lat2,long1,long2,Radius)\n",
    "            # append list\n",
    "            kiloList.append(distance)\n",
    "    # minimum value from the list\n",
    "    min_distance = min(kiloList)\n",
    "    # get index of minimum value\n",
    "    ind = kiloList.index(min_distance)\n",
    "    # get the warehouse based on the index found through minimum distance\n",
    "    actual_warehouse = warehouseList[ind]\n",
    "\n",
    "    if x['nearest_warehouse'] is np.nan:\n",
    "        return actual_warehouse\n",
    "    else:\n",
    "        return x['nearest_warehouse'] \n",
    "\n",
    "# apply fill_warehouse function on nearest_warehouse\n",
    "missing_data['nearest_warehouse'] = missing_data.apply(fill_warehouse, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 21: Fill distance to nearest warehouse.<br>\n",
    "Use methodology use in **\"Step 15: Check distance to nearest warehouse.\"**. Only difference here is we return distance to nearest warehouse name only for NaN or null values and existing values in column will remain same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_distance(x):\n",
    "    Radius = 6378 # Earth Radius\n",
    "    if x['nearest_warehouse'] == 'Nickolson':\n",
    "        # if nearest warehouse is Nickolson, get its coordinate\n",
    "        lat1 = radians(Nickolson['Nickolson'][0])\n",
    "        long1 = radians(Nickolson['Nickolson'][1])\n",
    "        \n",
    "    if x['nearest_warehouse'] == 'Thompson':\n",
    "        # if nearest warehouse is Thompson, get its coordinate\n",
    "        lat1 = radians(Thompson['Thompson'][0])\n",
    "        long1 = radians(Thompson['Thompson'][1])\n",
    "    \n",
    "    if x['nearest_warehouse'] == 'Bakers':\n",
    "        # if nearest warehouse is Bakers, get its coordinate\n",
    "        lat1 = radians(Bakers['Bakers'][0])\n",
    "        long1 = radians(Bakers['Bakers'][1])\n",
    "    # customer coordinates\n",
    "    lat2 = radians(x['customer_lat'])\n",
    "    long2 = radians(x['customer_long'])\n",
    "\n",
    "    longitude = long2 - long1\n",
    "    latitude = lat2 - lat1\n",
    "    # arc calculation\n",
    "    arc = (sin(latitude/2))**2 + cos(lat1) * cos(lat2) * (sin(longitude/2))**2\n",
    "    circumfrence = 2 * atan2(sqrt(arc), sqrt(1-arc))\n",
    "    # actual distance\n",
    "    actual_distance = Radius * circumfrence\n",
    "    \n",
    "    if x['distance_to_nearest_warehouse'] == 0: # if distance is zero, upadte the distance value\n",
    "        return round(actual_distance,4)\n",
    "    else:\n",
    "        return x['distance_to_nearest_warehouse'] # else keep the current distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all np.nan values with zero, as column is float and it's easy to read data with reolaced value\n",
    "missing_data['distance_to_nearest_warehouse'] = missing_data['distance_to_nearest_warehouse'].replace({np.nan:0})\n",
    "# apply fill_distance function on distance_to_nearest_warehouse\n",
    "missing_data['distance_to_nearest_warehouse'] = missing_data.apply(fill_distance, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 22: Fill happy Customer values.<br>\n",
    "Use same methodology used in **\"Step 16: Customer happiness\"**. Only difference here is we return happiness value (True or False) only for NaN or null values and existing values in column will remain same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 1, 0 to True and False boolean respectively\n",
    "missing_data['is_happy_customer'] = missing_data['is_happy_customer'].replace({1.0:True, 0.0:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data[missing_data['is_happy_customer'].isna()] # get the dataframe with NaN values in is_happy_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the NaN values with string 'None' for better analysis\n",
    "missing_data['is_happy_customer'] = missing_data['is_happy_customer'].replace({np.nan:'None'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(x):\n",
    "    sid = SentimentIntensityAnalyzer() # initilize object for polarity score\n",
    "    score = sid.polarity_scores(x['latest_customer_review']) # get the polarity score\n",
    "#       if score is >= 0.05, customer is happy\n",
    "    if score['compound'] >= 0.05:\n",
    "        if x['is_happy_customer'] == 'None': # Replace the empty cell with the value True\n",
    "            return True\n",
    "        else:\n",
    "            return x['is_happy_customer'] # else if cell is not empty keep current value\n",
    "    else: # customer is not happy\n",
    "        if x['is_happy_customer'] == 'None': # Replace the empty cell with the value True\n",
    "            return False\n",
    "        else:\n",
    "            return x['is_happy_customer'] # else if cell is not empty keep current value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply polarity function on is_happy_customer column and replace empty cells with calculated boolean value\n",
    "missing_data['is_happy_customer'] = missing_data.apply(polarity,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the brands in shopping cart in a list\n",
    "cart_list = []\n",
    "cart_dict = {}\n",
    "for items in dirty_data['shopping_cart']:\n",
    "    for item in eval(items):\n",
    "        cart_list.append(item[0])\n",
    "cartItems = set(cart_list)\n",
    "for x in cartItems:\n",
    "    cart_dict[x] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 23: Fill the Order Price.<br>\n",
    "To calculate the order price from items in cart we will use following steps:<br>\n",
    "1. Make a copy of missing_data.<br>\n",
    "2. Create new column **\"two_Items_shopping_cart\"** in copied dataframe. Having only those carts which have 2 branded items and replace remaining cart with NaN.<br>\n",
    "3. Now, remove all the NaN rows.<br>\n",
    "4. Sort all the itmes in the Shopping cart with branded item name.<br>\n",
    "5. Now sort the dataframe based on Shopping Cart column.<br>\n",
    "6. Drop duplicate values in shopping cart and reset the index.<br>\n",
    "7. Initiate a while loop to go through each cell of shopping cart.<br>\n",
    "8. Take the items in current row and compare it with the items of next row. If items in both rows are similar move to step 10.<br>\n",
    "9. If items are not similar, increment i and move to step 8 again.<br>\n",
    "10. Save items of current and next row in two list and get there price value.<br>\n",
    "11. Create an array with quantity of items from current and next row, and similarly for price.<br>\n",
    "12. Perform linear algebra using np.linalg.solve().<br>\n",
    "13. Store the item and its price in a dictionary. Check if item already in cart or not. Add only if not exists.<br>\n",
    "14. Repeat step from 8 to 13 until reach the condition where value of i is equal to length of dataframe. If yes exit the while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_copy = missing_data.copy() # make a copy of missing_data\n",
    "# Get all the cart with two brand items, and make other cart list as NaN\n",
    "missing_data_copy['two_Items_shopping_cart'] = missing_data_copy['shopping_cart'].apply(lambda x: x if len(eval(x))==2 else np.nan)\n",
    "# remove the rows with NaN values\n",
    "missing_data_copy.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to sort the shopping cart on the basis of branded items\n",
    "def sort_items(x):\n",
    "    # convert the string of list to list\n",
    "    items = eval(x['shopping_cart'])\n",
    "    # sort the list based on first element of tuples\n",
    "    items.sort(key = lambda x: x[0])\n",
    "    # return string of list\n",
    "    return str(items)\n",
    "\n",
    "# Sort the elements on the shopping cart\n",
    "missing_data_copy['shopping_cart'] = missing_data_copy.apply(sort_items, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort datafrmae based on shopping cart\n",
    "missing_data_copy.sort_values(by=['shopping_cart'], inplace=True)\n",
    "# drop all the duplicates to satisfy linear algebra equation\n",
    "missing_data_copy.drop_duplicates(subset=['shopping_cart'], inplace=True)\n",
    "# reseting the index\n",
    "missing_data_copy = missing_data_copy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dict = {} # define an empty\n",
    "# initialize i\n",
    "i = 0\n",
    "while True:\n",
    "    # convert the string of list to list\n",
    "    item_list = eval(missing_data_copy.loc[i,'shopping_cart'])\n",
    "    # get the items in cart for first list\n",
    "    item = [item_list[0][0], item_list[1][0]]\n",
    "    # get the second row of shopping cart\n",
    "    item_list_next = eval(missing_data_copy.loc[i+1,'shopping_cart'])\n",
    "    # get the items in next row of cart\n",
    "    item_next = [item_list_next[0][0], item_list_next[1][0]]\n",
    "\n",
    "    # if items in current row also exists in next row\n",
    "    if item[0] in item_next and item[1] in item_next:\n",
    "        # get the price for current row\n",
    "        price = (missing_data_copy.loc[i,'order_price'])\n",
    "        # get price for next row\n",
    "        price_next = missing_data_copy.loc[i+1,'order_price']\n",
    "        # creat array for linear algebra equation\n",
    "        a = np.array([[int(item_list[0][1]), int(item_list[1][1])], [int(item_list_next[0][1]),int(item_list_next[1][1])]])\n",
    "        # provide the price\n",
    "        b = np.array([price,price_next])\n",
    "        # price for items in shopping cart\n",
    "        x = np.linalg.solve(a, b)\n",
    "        # if item does not exist in dictionary, add with their respective price\n",
    "        if item[0] not in price_dict:\n",
    "            price_dict[item[0]] = x[0]\n",
    "        if item[1] not in price_dict:\n",
    "            price_dict[item[1]] = x[1]\n",
    "            \n",
    "        i+=1\n",
    "    else:\n",
    "        i+=1\n",
    "    # stop condition for while loop, once i reach value of length of dataframe\n",
    "    if i == missing_data_copy.shape[0]-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price of each branded item\n",
    "price_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 24: Fill Order Price.<br>\n",
    "1. Amount calculated in above step 23 for each item. Now we will calcuate the order price based on quantity of each item.<br>\n",
    "2. Convert the string of list to List. Initiate price=0.<br>\n",
    "3. Take the price of item from price_dict dictionary and multiply with it's quantity. Similarly do for all the items in that cart and add them together.<br>\n",
    "4. Replcae only NaN values and keep the current values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN value s with 0, as column is of type float\n",
    "missing_data['order_price'] = missing_data['order_price'].replace({np.nan:0})\n",
    "\n",
    "def fill_price(x):\n",
    "    # initialize price\n",
    "    price = 0\n",
    "    # get items in shopping cart as a list\n",
    "    items = eval(x['shopping_cart'])\n",
    "    for tup in items:\n",
    "        price += price_dict[tup[0]] * int(tup[1]) # multiply item price with quantity and increment price\n",
    "    if x['order_price'] == 0: # if cell is 0, update calculated price\n",
    "        return price\n",
    "    else:\n",
    "        return x['order_price'] # else return current price value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data['order_price'] = missing_data.apply(fill_price, axis=1) # apply fill price function on order_price column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 25: Fill delivery Charges<br>\n",
    "1. Take copy of missing data and select 'delivery_charges','season','distance_to_nearest_warehouse','is_expedited_delivery','is_happy_customer' columns only.<br>\n",
    "2. Now we will perform the linear regression to predict the delivery charges based on columns selected in above step.<br>\n",
    "3. Since we have categorical variable in dataset, we will convert them to numeric values using get_dummies() and store in dataframe.<br>\n",
    "4. Now take copy of above data frame, now we will make prediction on this copied dataframe.<br>\n",
    "5. Drop NaN from dataframe created in step 3.<br>\n",
    "6. Initialize liner model object.<br>\n",
    "7. Fit the model on dataframe created in step 3, excpect on the column delivery_charges as it is our target variable. Model will be fit on target variable delivery_charges.<br>\n",
    "8. make predictioin on dataframe created in step 4 and save it in main dataframe missing_data as predicted value.<br>\n",
    "9. Now we will replace the NaN using the predicted value.<br>\n",
    "10. If value already exist in cell, keep it, else replace it with predicted delivery_charges values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = missing_data.copy() # make a copy of missing data\n",
    "# get the required columns for prediction of delivery charges\n",
    "df_missing = df_missing[['delivery_charges','season','distance_to_nearest_warehouse','is_expedited_delivery','is_happy_customer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply get_dummies, as season is a categorical column, it will assign numeric values to categorical columns\n",
    "df_missing = pd.get_dummies(data=df_missing, drop_first=True)\n",
    "# make copy of the new dataframe\n",
    "prediction_data = df_missing.copy()\n",
    "# drop all the NaN rows from the data frame\n",
    "df_missing.dropna(subset=['delivery_charges'],axis=0,inplace=True)\n",
    "# Initialize Linear Regression object\n",
    "LR = LinearRegression()\n",
    "# Fit the data on df_missing dataframe\n",
    "LR.fit(df_missing[[x for x in df_missing.columns if x != 'delivery_charges']],df_missing['delivery_charges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(LR.predict(missing_data_impute.drop(['delivery_charges'],axis=1)))\n",
    "# Predict the delivery_charges on prediction_data, and add the predicted value in missing data frame\n",
    "missing_data['delivery_charges_predicted'] = LR.predict(prediction_data.drop(['delivery_charges'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the NaN values with 0 for better calculation\n",
    "missing_data['delivery_charges'] = missing_data['delivery_charges'].replace({np.nan:0})\n",
    "\n",
    "def fill_charges(x):\n",
    "    # if cell is zero replace it with predicted value\n",
    "    if x['delivery_charges'] == 0:\n",
    "        return x['delivery_charges_predicted']\n",
    "    else: # else keep the current value\n",
    "        return x['delivery_charges']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply fill_charges function on delivery_charges columns to fill the missing values\n",
    "missing_data['delivery_charges'] = missing_data.apply(fill_charges, axis=1)\n",
    "# drop delivery_charges_predicted column as it's not required\n",
    "missing_data.drop('delivery_charges_predicted', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 26: Fill Total Order Price.<br>\n",
    "We will use same methodology we use on **\"Step 12: Check Total Order Price\"**. Only replace the NaN values and keep the current values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the NaN values with 0 for better conditions\n",
    "missing_data['order_total'] = missing_data['order_total'].replace({np.nan:0})\n",
    "\n",
    "def fill_total(x):\n",
    "    # Calculate the total order price\n",
    "    order_total = x['order_price']*(1-x['coupon_discount']/100)+x['delivery_charges']\n",
    "    \n",
    "    if x['order_total'] == 0: # if order price is zero, replace it with calcuated total order price\n",
    "        return order_total\n",
    "    else:\n",
    "        return x['order_total'] # else keep the current value of cell\n",
    "\n",
    "# apply fill_total on order_total column \n",
    "missing_data['order_total'] = missing_data.apply(fill_total, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the filled Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.to_csv('30749476_missing_data_solution.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data = pd.read_csv('30749476_outlier_data.csv') # Read Outlier Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 27: Summary of Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_data.describe() # Analyze the Numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 28: Plot Box plot to check Outliers for delivery_charges Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=1, figsize=(25, 10), dpi=150, facecolor='g', edgecolor='k') # size of plot setting\n",
    "bp = outlier_data.boxplot(column='delivery_charges') # box plot for delivery_charges column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 29: Use Interquartile to detect Outliers<br>\n",
    "1. First get the IQR value by subtracting Q3 and Q1 percentile value.<br>\n",
    "2. Save the summmary of numeric col in dataframe.<br>\n",
    "3. Select quartile value from 75% and 25%.<br>\n",
    "4. Calculate upper and lower range by adding 1.5xIQR to 75% precentile and subtracting it from 25% percentile respectively.<br>\n",
    "5. Now filter the Outlier data based on upper and lower range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR for delivery_charges columns\n",
    "Q3, Q1 = np.percentile(outlier_data['delivery_charges'], [75 ,25])\n",
    "iqr = Q3 - Q1\n",
    "\n",
    "df = outlier_data.describe()\n",
    "\n",
    "quartile_75 = df.loc['75%','delivery_charges']\n",
    "\n",
    "quartile_25 = df.loc['25%','delivery_charges']\n",
    "\n",
    "Upper_Range = quartile_75 + 1.5*iqr\n",
    "Lower_Range = quartile_25 - 1.5*iqr\n",
    "\n",
    "outlier_removed = outlier_data[outlier_data['delivery_charges'] >= Lower_Range]\n",
    "outlier_removed = outlier_removed[outlier_removed['delivery_charges'] <= Upper_Range]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data after removing Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_removed.to_csv('30749476_outlier_data_solution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
